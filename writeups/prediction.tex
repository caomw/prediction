% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode


\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)


\usepackage{geometry} % to change the page dimensions
\geometry{letterpaper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

% additional packages for math typesetting
\usepackage{amsmath}
\usepackage{amsfonts}


\newcommand{\R}{\mathbb{R}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\Rel}{\mathbb{Z}}
\newcommand{\Int}{\mathbb{N}}
\newcommand{\Eff}{\mathcal{E}}
\newcommand{\Compl}{\mathscr{C}}

\title{Prediction and Inverse Problems in Dynamical Systems}
\author{Joan Bruna, Pablo Sprechmann}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\section*{Introduction}

Extracting information from unlabeled data remains the main challenge of unsupervised learning. 
In this work we consider semi-supervised learning, in which one observes the evolution of a dynamical system 
and attempts to learn through the underlying dynamics. 
The main strategy to understand the dynamics is by linearizing them through an appropriate non-linear representation.

This work considers the setting of speech and temporal video data. 
There are two main taks we are interested in: prediction and source separation/denoising. 
Other works on NLP have shown that training systems to perform prediction is a very effective surrogate that 
can be applied to other tasks, such as recognition. On the other hand, source separation is a major application
of speech representations that requires exploiting the temporal coherence of different sources. 

Dynamics can be learnt with a variety of models. The simplest are Kalman Filter and Hidden Markov Models, which
learn dynamics in the form of linear equations, assuming Gaussian distributions in the former and discrete variables in the latter. 
On the other hand, recent works on speech and natural language processing have developed Recurrent Neural Networks (RNNs), 
which the capacity to learn more complex nonlinear dynamics. 

Our objective is to develop a model which progressively moves from linear to RNNs, which keeps the interpretability but also 
handles non-linear dynamics. 
Since we are interested in inverse problems, models need to be generative. 

Summary of contributions:
\begin{itemize}
\item bla 
\item bla
\end{itemize}


\section{Linearizing Dynamics}

\subsection{Linear NMF Dynamics}

This is the basic first model:
\begin{eqnarray}
\min_{z_t, A, D} \| x_t - D z_t \|^2 + \lambda \|z_t \|_1 + \mu \|z_t - A z_{t-1} \|^2
\end{eqnarray}

Properties:
\begin{itemize}
\item + Easy to train, compact model with few parameters
\item + Gives good results on source separation
\item + It is easily interpreted as a sparse Kalman FIlter.
\item - The model has a fundamental limitation in that the dynamics on the hidden states are assumed linear. 
\item - All the uncertainty/inference power in the model is in the latent variables $z_t$. The temporal relationship is rigid and given by
a single linear operator $A$.
\item - Optimiziation is too ``easy": there are many local minima, and the objective function is not directly optimizing what we want.
\end{itemize}

\subsection{Bilevel Linear NMF}

A modification of the previous model is to train it discriminatively to predict the next frame:

If we denote 
$$z*_t(D, A, x) = \argmin_z \| x_t - D z_t \|^2 + \|z_t \|_1 +  \| z_t - A z_{t-1} \|^2~,$$
we optimize
$$\min_{D, A, E} \| x_{t+1} - E z*_t(D, A, x) \|^2~.$$

(Lista version) also 


\subsection{Linear Pooling NMF}

\subsection{Bi-Linear NMF}

\section{Examples: Newton Dynamics, Jitter}

\section{Pooling and Scattering}

\section{Relationship to Previous work}

Cedric et al. Linear dynamics on NMF. 

RNN for music

RNN for speech recognition (Graves et al). 

Yann's papers.

\section{Experimental Results}

Prediction

Source Separation.





Important points:

\begin{itemize}
\item deformation operators are phase modulations 
\item proximal operators
\item link with optical flow estimation
\item cascade: we must show at least two layers of prediciton.
\item scattering; link with commutation error.
\item deep network performs gradient steps of a proximal operator: this ressembles LISTA.
\item causal vs non-causal
\item relationship with RNN
\item Consider a model: jitter, local deformations. Can I prove things there? What is the optimum system?
\end{itemize}



\end{document}







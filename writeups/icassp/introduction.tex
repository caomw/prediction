\section{Introduction}

The problem of isolating or enhancing a speech signal recorded in a noisy environment has been widely
studied in the audio processing community \cite{loizou2007speech,hansler2008speech}. It becomes particularly challenging in the presences of 
non-stationary background noise, which is a very common situation in many applications encountered, e.g., in telephony.
We approach this problem as a monaural source separation method
by modeling the speech as one source, and the noise as the other.
This is a natural approach when the characteristics of both the signal of interest and the noise vary throughout time \cite{WilsonRSD08,JoderWEVS12,MysoreS11,DuanMS12}.
%Consequently, many works have used source separation techniques for addressing this problem,

The decomposition of time-frequency representations, such as the power or magnitude spectrogram
in terms of elementary atoms of a dictionary, has become a popular tool in audio processing. 
Non-negative matrix factorization (NMF) \cite{NMF, smaragdis2006probabilistic},
have been widely adopted in various audio processing tasks, including in particular source separation, see \cite{smaragdis2014static} for a recent review. 
There are many works that follow this line in speech separation \cite{schmidt06speechseparation,shashanka_icassp07} and enhancement \cite{JoderWEVS12,DuanMS12,schmidt07mlsp,mohammadiha2013supervised}. %and robust automatic speech recognition \cite{GemmekeVH11,WeningerWGSGHVR12},
%among many others.
%bandwidth extension \cite{BansalRS05,HanMP12} and speaker recognition \cite{wu2010robust,joder2012exploring}.

%NMF and PLCA produce high quality separation results when the dictionaries
%for different sources are sufficiently distinct.
%There is naturally a compromise between the approximation
%of the training data and tightness of the model: the more general is the dictionary the higher is the chance it will include elements that
%match spectral patterns in the competing sources.
%In order to mitigate this problem, recent approaches have proposed
%alternative models constraining the solution in meaningful ways,
%as for example, by imposing sparsity of the activations \cite{shashanka_icassp07,hoyer2004non}.
%

In plain NMF, signals that can be well approximated with the learned dictionary are
likely to resemble the training data on a frame by frame manner. They might, however, 
not be globally consistent. Standard NMF approaches treat different time-frames independently, ignoring the 
temporal dynamics of the signals. In other words, there is additional structure in speech at a time-scale larger than
the frame-length that cannot be learned (or exploited) with NMF. In order to overcome this limitation,  
%and achieve consistency at a larger temporal scale,
many works have proposed regularized extensions of NMF to promote learned (or designed) structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients \cite{fevotte2011majorization}, including  co-occurrence statistics of the basis functions \cite{WilsonRSD08}, and learned temporal dynamics \cite{MysoreS11,HanMP12,icassp13a,mohammadiha2013nonnegative}.
%Recent studies have proposed regularized variants of NMF or PLCA trying to overcome this limitation,


We propose to think of the NMF-based unmixing process as the concatenation of two operators.
First, the signal is represented in a feature space given by a poolled analysis operator given: the magnitude of a time-frequency representation such
as the Short-Time Fourier Transform (STFT). Then a synthesis operator, given by the dictionary learning stage, is applied to produce an unmixing in the feature space.
Finally, the separation is obtained by inverting these representations. Performing the separation in the pooled representation is key to the success of the algorithm. The magnitude STFT is in general sparse (simplifying the separation process) and invariant to variations in the phase (relieving the NMF from
learning this irrelevant variability). This comes at the expense of inverting a pooled unmixing in the feature space, normally known as the
phase recovery problem \cite{XX}. In the case of standard NMF, this is easily done via Wiener filtering technique discussed in Section \ref{sec:nmf}.

In this work, rather than seeking for a coding scheme with temporal regularity, we seek to encode a representation of the audio signal at a larger scale in which
natrual variability in speech is highly compressible. A sensibly designed scattering transform can compress changes that are temporally consistent with a speech singal, e.g. smooth changes in pitch and envelope. A dictionary learnt to represent the signal in this deep representation would implicitly be learning the short term temporal dynamics of the signal.

Scattering transforms have recently been introduced \cite{XX} to represent audio signals and images, achieving state-of-the-art results for texture discrimination, and music genre recognition \cite{XX}. A scattering transform iterates on complex wavelet transforms and modulus operators which compute their envelop. It has close relations with psychophysical and physiological models \cite{XX}. %Their success in audio classification comes from the fact that they can reduce the intra class variability (like temporal redundancy).

Our claim is that an important part of the consistency that is imposed via structured NMF, can be eliminated with a better signal representation.
In this new setting one can learn the temporal dynamics with a very simple NMF encoding. However, the problem that becomes
more difficult is that of inverting the representation. Recent studies in textured sound synthesis from scattering
moments have solved this problem successfully using gradient descent algorithms \cite{bruna2013audio}.

Synthesis models with coherent dictionaries are known to be highly unstable representations \cite{jenatton2012local}. 
Thus, training them to satisfy slowness and temporal consistency can be challenging. For example, in \cite{icassp13a}
the authors explain that the learning the temporal dynamics in NMF via a Kalman type of model, can become very difficult
when the coding is sparse due to the instability and jitter in the codes.
In contrast, analysis operators are sable by construction.

%In all these methods the audio signal is represented as a non-negative and the demixng is obtained  model is expressed as the minimization of a cost with a data fitting term and some structure-promoting penalties.



